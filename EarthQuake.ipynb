{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Name: Aniket Kale\n",
    "* Deep learning Challenge    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23412, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "data = pd.read_csv(\"earthquake_data.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>NormalizedLat</th>\n",
       "      <th>NormalizedLong</th>\n",
       "      <th>NormalizedDepth</th>\n",
       "      <th>NormalizedMag</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Latitude_max_min</th>\n",
       "      <th>Longitude_max_min</th>\n",
       "      <th>Depth_max_min</th>\n",
       "      <th>Magnitude_max_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23744.00</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>19.246</td>\n",
       "      <td>145.616</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>131.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.590649</td>\n",
       "      <td>0.904493</td>\n",
       "      <td>0.189274</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>min</td>\n",
       "      <td>-77.080</td>\n",
       "      <td>-179.997</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23746.00</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>1.863</td>\n",
       "      <td>127.352</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.484060</td>\n",
       "      <td>0.853759</td>\n",
       "      <td>0.115675</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>max</td>\n",
       "      <td>86.005</td>\n",
       "      <td>179.998</td>\n",
       "      <td>700.0</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23747.00</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>-20.579</td>\n",
       "      <td>-173.972</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.346451</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.030096</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23750.00</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>-59.076</td>\n",
       "      <td>-23.557</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.110396</td>\n",
       "      <td>0.434562</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23751.00</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>11.938</td>\n",
       "      <td>126.427</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.545838</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date    Time  Latitude  Longitude        Type  Depth  Magnitude  \\\n",
       "0  23744.00  0.5724    19.246    145.616  Earthquake  131.6        6.0   \n",
       "1  23746.00  0.4790     1.863    127.352  Earthquake   80.0        5.8   \n",
       "2  23747.00  0.7541   -20.579   -173.972  Earthquake   20.0        6.2   \n",
       "3  23750.00  0.7845   -59.076    -23.557  Earthquake   15.0        5.8   \n",
       "4  23751.00  0.5645    11.938    126.427  Earthquake   15.0        5.8   \n",
       "\n",
       "   NormalizedLat  NormalizedLong  NormalizedDepth  NormalizedMag  Unnamed: 11  \\\n",
       "0       0.590649        0.904493         0.189274       0.138889          NaN   \n",
       "1       0.484060        0.853759         0.115675       0.083333          NaN   \n",
       "2       0.346451        0.016736         0.030096       0.194444          NaN   \n",
       "3       0.110396        0.434562         0.022964       0.083333          NaN   \n",
       "4       0.545838        0.851190         0.022964       0.083333          NaN   \n",
       "\n",
       "   Unnamed: 12 Unnamed: 13  Latitude_max_min  Longitude_max_min  \\\n",
       "0          NaN         min           -77.080           -179.997   \n",
       "1          NaN         max            86.005            179.998   \n",
       "2          NaN         NaN               NaN                NaN   \n",
       "3          NaN         NaN               NaN                NaN   \n",
       "4          NaN         NaN               NaN                NaN   \n",
       "\n",
       "   Depth_max_min  Magnitude_max_min  \n",
       "0           -1.1                5.5  \n",
       "1          700.0                9.1  \n",
       "2            NaN                NaN  \n",
       "3            NaN                NaN  \n",
       "4            NaN                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Earthquake           23232\n",
       "Nuclear Explosion      175\n",
       "Explosion                4\n",
       "Rock Burst               1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                     0\n",
       "Time                     0\n",
       "Latitude                 0\n",
       "Longitude                0\n",
       "Type                     0\n",
       "Depth                    0\n",
       "Magnitude                0\n",
       "NormalizedLat            0\n",
       "NormalizedLong           0\n",
       "NormalizedDepth          0\n",
       "NormalizedMag            0\n",
       "Unnamed: 11          23412\n",
       "Unnamed: 12          23412\n",
       "Unnamed: 13          23410\n",
       "Latitude_max_min     23410\n",
       "Longitude_max_min    23410\n",
       "Depth_max_min        23410\n",
       "Magnitude_max_min    23410\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  select some important cols\n",
    "col1 = data[[\"Latitude\",\"Longitude\", \"Depth\"]]\n",
    "col2= data[\"Magnitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6.0\n",
       "1    5.8\n",
       "2    6.2\n",
       "3    5.8\n",
       "4    5.8\n",
       "Name: Magnitude, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1.head()\n",
    "col2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to Numpy Matrix\n",
    "InputX = col1.as_matrix()\n",
    "Inputy = col2.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.   5.8  6.2 ...,  5.9  6.3  5.5]\n"
     ]
    }
   ],
   "source": [
    "print(Inputy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6. ,  5.8,  6.2, ...,  5.9,  6.3,  5.5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputX.astype(float, copy = False)\n",
    "Inputy.astype(float, copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_minimum [ -77.08  -179.997   -1.1  ]\n",
      "X_maximum [  86.005  179.998  700.   ]\n",
      "y_minimum 5.5\n",
      "y_maximum 9.1\n"
     ]
    }
   ],
   "source": [
    "# Min and Max Normalization\n",
    "X_min = np.amin(InputX,0)\n",
    "X_max = np.amax(InputX,0)\n",
    "y_min = np.amin(Inputy,0)\n",
    "y_max = np.amax(Inputy,0)\n",
    "print(\"X_minimum\", X_min)\n",
    "print(\"X_maximum\", X_max)\n",
    "print(\"y_minimum\", y_min)\n",
    "print(\"y_maximum\", y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59064905  0.90449312  0.189274  ]\n",
      " [ 0.48406046  0.85375908  0.11567537]\n",
      " [ 0.34645124  0.01673634  0.03009556]\n",
      " ..., \n",
      " [ 0.69900911  0.89007681  0.01583226]\n",
      " [ 0.41727749  0.82962513  0.11424904]\n",
      " [ 0.70194868  0.89281046  0.01859934]]\n"
     ]
    }
   ],
   "source": [
    "# we will normalize data\n",
    "InputX_norm = (InputX-X_min)/ (X_max-X_min)\n",
    "print(InputX_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we Dont need to do Normalization in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inputy_norm = Inputy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape\n",
    "X_feature = 3\n",
    "y_feature = 1\n",
    "sample = 23000 # Number of samples\n",
    "InputX_reshape = np.resize(InputX_norm,(sample,X_feature))\n",
    "Inputy_reshape = np.resize(Inputy_norm,(sample,y_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23000, 3)\n",
      "(23412,)\n"
     ]
    }
   ],
   "source": [
    "print(InputX_reshape.shape)\n",
    "print(Inputy_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will split training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Data\n",
    "batch_size = 20000\n",
    "InputX_train = InputX_reshape[0:batch_size,:]\n",
    "InputX_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inputy_train = Inputy_reshape[0:batch_size,:]\n",
    "Inputy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation data\n",
    "v_size = 2500\n",
    "InputX_test = InputX_reshape[batch_size: batch_size+v_size,:]\n",
    "InputX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inputy_test = Inputy_reshape[batch_size: batch_size+v_size,:]\n",
    "Inputy_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Hyper Parameter\n",
    "learning_rate = 0.01\n",
    "training_iterations = 10000\n",
    "display_iterations = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input \n",
    "X = tf.placeholder(tf.float32,shape=(None,X_feature))\n",
    "# output\n",
    "y = tf.placeholder(tf.float32, shape=(None,y_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L1 = 3 # Number of neurons in first layer\n",
    "L2 = 3\n",
    "L3 = 3\n",
    "# layer one weights\n",
    "w_fc1 = tf.Variable(tf.random_uniform([X_feature,L1]))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[3]))\n",
    "#Layer2 weights\n",
    "w_fc2 = tf.Variable(tf.random_uniform([L1,L2]))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[L2]))\n",
    "# Layer 3 \n",
    "w_fc3 = tf.Variable(tf.random_uniform([L2,L3]))\n",
    "b_fc3 = tf.Variable(tf.constant(0.1, shape=[L3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output layer\n",
    "W_fo = tf.Variable(tf.random_uniform([L3,y_feature]))\n",
    "b_fo = tf.Variable(tf.constant(0.1,shape=[y_feature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matmul Layer 1\n",
    "matmul_fc1 = tf.matmul(X,w_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(matmul_fc1) # Relu activation\n",
    "# layer 2\n",
    "matmul_fc2 = tf.matmul(h_fc1,w_fc2) + b_fc2\n",
    "h_fc2 = tf.nn.relu(matmul_fc2)\n",
    "# layer 3\n",
    "matmul_fc3 = tf.matmul(h_fc2,w_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(matmul_fc3)\n",
    "\n",
    "# output layer\n",
    "matmul_fc4 = tf.matmul(h_fc3,W_fo) + b_fo\n",
    "output_layer = matmul_fc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "mean_sq = tf.reduce_mean(tf.square(y-output_layer))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_sq)\n",
    "# operation sanve in saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initilization and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Loss: [19.4172]\n",
      "Training_loss is : 17.8549 at_iteration: 0\n",
      "validation_loss is : 17.9292 at_iteration: 0\n",
      "Model saved in file: /tmp/earthquake_model.ckpt\n",
      "final_training_loss: 0.176184\n",
      "final_validation_loss 0.187261\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Training_Loss:\", sess.run([mean_sq], feed_dict={X:InputX_train,y:Inputy_train}))\n",
    "    for i in range(training_iterations):\n",
    "        sess.run([train_step], feed_dict={X:InputX_train,y:Inputy_train})\n",
    "        if i%display_iterations ==0:\n",
    "            print(\"Training_loss is :\", sess.run(mean_sq, feed_dict={X:InputX_train,y:Inputy_train}),\"at_iteration:\", i)\n",
    "            print(\"validation_loss is :\", sess.run(mean_sq, feed_dict={X:InputX_test, y:Inputy_test}),\"at_iteration:\", i)\n",
    "    # save variable\n",
    "    save_path = saver.save(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    # final training loss\n",
    "    print(\"final_training_loss:\", sess.run(mean_sq, feed_dict={X:InputX_train, y:Inputy_train}))\n",
    "    print(\"final_validation_loss\", sess.run(mean_sq, feed_dict={X:InputX_test, y:Inputy_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter latitude between -77 to 86 :70\n",
      "Enter Longitude between -180 to 180:170\n",
      "Enter Depth between 0 to 700:600\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4162c8bbd56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Longitude between -180 to 180:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter Depth between 0 to 700:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mInputX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mInputX2_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mInputX2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_max\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mInputX1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputX2_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing data\n",
    "lat = input(\"Enter latitude between -77 to 86 :\")\n",
    "long = input(\"Enter Longitude between -180 to 180:\")\n",
    "depth = input(\"Enter Depth between 0 to 700:\")\n",
    "InputX2 = np.asarray([lat, long, depth], dtype = np.float32)\n",
    "InputX2_norm = (InputX2-X_min)/ (X_max-X_min)\n",
    "InputX1_test = np.resize(InputX2_norm,(1,X_feature))\n",
    "with tf.Session() as sess:\n",
    "        saver.restore(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "        print(\"Model Restored.\")\n",
    "        print(\"output:\", sess.run([output_layer], feed_dict={X:InputX1_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our output is 5.90 Earthquak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
